from langchain_openai import ChatOpenAI
from langchain.agents import initialize_agent, Tool
from langchain_community.tools import DuckDuckGoSearchRun
from utils.schemas import RawMeasurement
import json, os
import re


OPENAI_API_KEY=""
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.2,
    openai_api_key=OPENAI_API_KEY
)


# Build the prompt
def build_prompt(data: dict) -> str:
    user_question = data.get("input", "")
    devices = data.get("devices", [])

    prompt_parts = [
        "Sen bir enerji verimliliÄŸi danÄ±ÅŸmanÄ±sÄ±n. AÅŸaÄŸÄ±da kullanÄ±cÄ± tarafÄ±ndan girilmiÅŸ cihaz bilgileri, teknik dÃ¶kÃ¼man iÃ§erikleri ve kullanÄ±cÄ± notlarÄ± yer alÄ±yor. Bu bilgilere dayanarak akÄ±llÄ± cevaplar ver.\n"
    ]

    for i, dev in enumerate(devices, 1):
        prompt_parts.append(f"\nğŸ”¹ Cihaz {i}")
        prompt_parts.append(f"Cihaz AdÄ±: {dev.get('cihaz_adi', '-')}")
        prompt_parts.append(f"Cihaz ID: {dev.get('Cihaz_id', '-')}")
        prompt_parts.append(f"Breaker ID: {dev.get('breaker_id', '-')}")
        prompt_parts.append(f"YÃ¼klenen PDF: {dev.get('cihaz_pdf', '-')}")

        not_ = dev.get("kullanici_promptu", "")
        if not_:
            prompt_parts.append(f"KullanÄ±cÄ± Notu: {not_}")

        text = dev.get("pdf_text", "")
        if text:
            prompt_parts.append("PDF Teknik Ä°Ã§eriÄŸi:\n" + text[:2000] + "\n---")

    prompt_parts.append(f"\nKullanÄ±cÄ±nÄ±n Sorusu: {user_question}")
    return "\n".join(prompt_parts)


#  Fix the LLM output
def fix_output(text: str) -> str:
    # Liste baÅŸlÄ±klarÄ±nÄ± dÃ¼zgÃ¼n ayÄ±r
    text = re.sub(r"(\d)\.(\S)", r"\1. \2", text)
    text = re.sub(r"(\d\.\s)([A-ZÃ‡ÄÄ°Ã–ÅÃœ])", r"\n\n\1\2", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = re.sub(r"[ ]{2,}", " ", text)

    # Nokta eksikse ekle
    lines = text.splitlines()
    fixed_lines = []
    for line in lines:
        line = line.strip()
        if line and not line.endswith((".", ":", "-", "â€¦")):
            if not re.match(r"\d+\.\s", line):
                line += "."
        fixed_lines.append(line)

    return "\n".join(fixed_lines).strip()


# Ana LLM Ã§aÄŸÄ±rÄ±cÄ±
def invoke(data: dict):
    final_prompt = build_prompt(data)

    raw_output = llm.invoke(final_prompt)
    clean_output = fix_output(raw_output.content)

    return {"output": clean_output}